{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-08T16:00:08.430609Z",
     "start_time": "2017-03-08T17:00:08.426569+01:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# My Mixed Integer Programming approach for the first round of Google HashCode 2017\n",
    "## Or: how Google has a nice library for optimization problems, but the documentation kinda sucks \n",
    "\n",
    "### The challenge\n",
    "\n",
    "Here is a summary of the challenge proposed for the first round of hashcode 2017, a more in depth explanation can be found in the [problem pdf](files/hashcode2017_streaming_videos.pdf)\n",
    "\n",
    "It is given a net, with a datacenter, a series of cache servers, and a series of clients (or endpoints) connected to the datacenter and to 0 or more cache servers. each connection between a client and a cache/datacenter has a constant latency, and one cache server can be connected to one or more clients.\n",
    "\n",
    "In the datacenter there are some videos, each having a fixed dimension, available to all clients.\n",
    "\n",
    "Having a list of request for a video from a client, what is the best way to cache these video in the cache servers?\n",
    "to score a solution one sums the time saved for each request, and divides by the total number of requests\n",
    "\n",
    "### My approach\n",
    "\n",
    "I took the road of the optimization of an integral problem: I framed the problem in a mathematical view, with a linear function to maximize (the scoring function), a set of linear constrain to describe the problem, and a set of variables that can only assume integer values. Given this formulation, there are well known algorithms that operate on the variable to find the best solution possible for the original problem.\n",
    "\n",
    "Google has a collection of those algorithms under this library: [Google Optimization Tools](https://developers.google.com/optimization/)\n",
    "Documentation is a bit lacking, and usage is a bit difficult without a basic knowledge of the subject. \n",
    "On the plus side it comes with a python binding, and this greatly helps in a jupyter notebook\n",
    "\n",
    "### Notes \n",
    "\n",
    "I did implement a complete solution, but I cannot compute the solution beyond the smallest dataset because this approach is very taxing in memory requirement and time complexity, I believe the general algorithm is O(n^4).\n",
    "\n",
    "In this problem ```N``` is mostly the number of requests, as this usually dwarfs the number of videos and the number of caches. Each cache generates only a constrain with a cardinality of the number of videos, while each request generates a constrain of costant cardinality for each cache connected to the request's endpoint.\n",
    "\n",
    "I think a mixed heuristic approach could provide with a great score while mantaining a very low computational cost. One possibility could be to sort the request in order of descending profitability, and to generate an optimal solution using only at most ```k``` of the most profitable requests. Found a solution, a new problem can be formulated by prepopulating the caches with this solution and a new subsets of the unused requests, to compute a new improved (but not optimal) solution, that can be used in a new iteration util all the caches are full, or a iteration threshold is achieved.\n",
    "\n",
    "#### Techical Note\n",
    "\n",
    "[Google Optimization Tools](https://developers.google.com/optimization/) is a c++ library that has to be compiled. Under linux it's a simple ```make install```, so this should not be a problem.\n",
    "\n",
    "Note: Here i use the MPI solver. The CP solver can be used in the same way the mip solver is used in through this notebook. the only difference is in the instantiation, done with these calls:\n",
    "\n",
    "    # Instantiate a CP solver.\n",
    "    parameters = pywrapcp.Solver.DefaultSolverParameters()\n",
    "    solver = pywrapcp.Solver(\"simple_CP\", parameters)\n",
    "    and the fact that the decision vars have to be collected in a list to be passed to a decision tree\n",
    "    #the examples used CHOOSE_FIRST_UNBOUND and ASSIGN_MIN_VALUE. obsly no explanation on the meanings \"-_-\n",
    "    decision_builder = solver.Phase(decision_vars, solver.CHOOSE_LOWEST_MIN,\n",
    "                                solver.ASSIGN_MAX_VALUE)\n",
    "\n",
    "and the solutions are provided through a collector\n",
    "\n",
    "    # Create a solution collector.\n",
    "    collector = solver.LastSolutionCollector()\n",
    "    # Add the decision variables.\n",
    "    for dv in decision_vars:\n",
    "        collector.Add(dv)\n",
    "    # Add the objective.\n",
    "    collector.AddObjective(obj_expr)\n",
    "        solver.Solve(decision_builder, [objective, collector])\n",
    "\n",
    "[this](https://developers.google.com/optimization/assignment/compare_mip_cp) page does a good job highlighting the difference of the two approach\n",
    "for this problem, the mip approach is faster but requires more memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### And now for some code\n",
    "\n",
    "Let's start with a bit of modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-15T12:24:55.774727Z",
     "start_time": "2017-03-15T13:24:55.742813+01:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#size is the capacity of the cache in Mb, ID is an integer\n",
    "class Cache:\n",
    "    def __init__(self, size, ID):\n",
    "        self.size = size\n",
    "        self.ID = ID\n",
    "\n",
    "#like Cache, size is dimension in Mb, ID is an integer\n",
    "class Video:\n",
    "    def __init__(self, size, ID):\n",
    "        self.size = size\n",
    "        self.ID = ID\n",
    "\n",
    "#Endpoint represent a client that generate a request, has an ID, a latency towards the datacenter\n",
    "#and a list of pairs (Cache, latency) that represents the chaches to which is connected, \n",
    "#and the latency of this connection\n",
    "class Endpoint:\n",
    "    def __init__(self, datacenter_latency, caches_latency, ID):\n",
    "        self.ID = ID\n",
    "        self.datacenter_latency = datacenter_latency\n",
    "        self.caches_latency = caches_latency\n",
    "\n",
    "#A request has a starting endpoint, a target video, \n",
    "#and a cardinality (how many times the video is requested) represented as an int\n",
    "class Request:\n",
    "    def __init__(self, quantity, video, endpoint):\n",
    "        self.quantity = quantity\n",
    "        self.video = video\n",
    "        self.endpoint = endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### TDD\n",
    "\n",
    "Before writing the solution function, it's good to write the verifier for a solution. This will help also to define what we want as a result.\n",
    "\n",
    "(note: of course i wrote the verifier *after* i wrote rewrote the solution function)\n",
    "(note: this is far from the best way to write a verifier, i know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-15T12:24:56.020430Z",
     "start_time": "2017-03-15T13:24:55.778703+01:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from functools import reduce\n",
    "\n",
    "#value is the calculated score, res is a map cache:list(video)\n",
    "#where each cache is paired with the videos it will contain\n",
    "#requestList is the list of request as given in input to the problem, to compute the score\n",
    "def verifySolution(value, res, requestList):\n",
    "    #verify that the videos assigned to a cache can fit inside it\n",
    "    print(\"all the video from the solution fit into the caches: \",\n",
    "          all(\n",
    "              map(lambda x: x[0].size >= sum(map(attrgetter('size'), x[1])),\n",
    "                  res.items())))\n",
    "    \n",
    "    #compute the score by multiplying each request cardinality with the saved time \n",
    "    #(latency to datacenter minus the lowest latency to a cache containing the video)\n",
    "    #and divinding by the sum of the cardinality of all requests \n",
    "    #(the result is multiplied by 1000 and rounded down as per instructions) \n",
    "    score_l = []\n",
    "    for r in requestList:\n",
    "        dc_l = r.endpoint.datacenter_latency\n",
    "        c_l = r.endpoint.caches_latency\n",
    "        saved_t = r.endpoint.datacenter_latency - min([dc_l] + list(\n",
    "            map(itemgetter(1), filter(lambda x: r.video in res[x[0]], c_l))))\n",
    "        score_l.append((r.quantity * saved_t, r.quantity))\n",
    "\n",
    "    tmp = reduce(lambda a, b: (a[0] + b[0], a[1] + b[1]), score_l)\n",
    "    print(\"actual score: \", floor(1000 * tmp[0] / tmp[1]))\n",
    "    print(\"score from the mpiSolver: \", floor(value))\n",
    "    \n",
    "#a nice summary printer\n",
    "def summaryPrinter(value, res):\n",
    "    print('score: ', value)\n",
    "    for c, vl in res.items():\n",
    "        print('in cache %d are present %s' %\n",
    "              (c.ID,\n",
    "               ', '.join(map(lambda x: 'video%d' % (x.ID), vl))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# The interesting Integer Linear Programming bit\n",
    "\n",
    "Finally the central part. this is the sum of an afternoon of exploring and learning to use the library on this notebook, and a couple of days to debug it/make it usable.\n",
    "\n",
    "One important bit that i noticed is this: the documentation doesn't make clear that there are multiple ways to define the problem, and that a problem written for the mpi solver can be almost painlessly (more on this later) converted to a cp solver. It is a rabbit hole, and for sure I haven't yet discovered the most idiomatic way to input the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-15T12:24:56.276544Z",
     "start_time": "2017-03-15T13:24:56.023514+01:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "def mpiSolver(videoList, cacheList, endpointList, requestList):\n",
    "    # Instantiate a MPI solver. give it a name, and choose the uderling implementation (this is the default, more can be installed)\n",
    "    solver = pywraplp.Solver('Cache allocation problem',\n",
    "                             pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING)\n",
    "\n",
    "    #create a matrix of intvar y[cache_i, video_j], and put a constrain on space usage of a cache\n",
    "    #each y can be 1 if video_j is present on cache_i, or 0 otherwise\n",
    "    #cache_video will be a map cache:list(pair(video, IntVar))\n",
    "    cache_video = {}\n",
    "    for c in cacheList:\n",
    "        cache_video_vars = {\n",
    "            #IntVar is what the solver will vary to find a solution. we create it, and use it to define constraints\n",
    "            #it get a range and a name for debug purposes. Note: this name should be unique, otherwise crashes happens\n",
    "            v: solver.IntVar(0, 1, 'v:%d_c:%d' % (v.ID, c.ID))\n",
    "            for v in videoList\n",
    "        }\n",
    "        #Here i'm telling the solver: the size of all the videos you decide to put in the cache should fit into the cache size.\n",
    "        #notice the nice way to express it via operator overloading builtin in the library\n",
    "        #solver.Sum does not suffer from recursion depth limit like the builtin sum (did not investigate the root causes tough)\n",
    "        solver.Add(\n",
    "            solver.Sum(\n",
    "                map(lambda x: x[0].size * x[1], cache_video_vars.items())) <=\n",
    "            c.size)\n",
    "        cache_video[c] = cache_video_vars\n",
    "        \n",
    "        \n",
    "    #request_min_latency is a support intvar that represents for each request \n",
    "    #the minimum latency between all the caches (and datacenter) connected to the endpoint that contains the video\n",
    "    #req_var is a map request:IntVar\n",
    "    req_var = {}\n",
    "    for r in requestList:\n",
    "        dc_L = r.endpoint.datacenter_latency\n",
    "        #here again i use a IntVar. i could use a NumVar to represent a var that can have Real (instead of Int) values\n",
    "        #but this way it's faster, and for this problem the found solution it's fine\n",
    "        #the range is from 0 to the datacenter latency of the request's endpoint\n",
    "        req_min_latency = solver.IntVar(0, dc_L, 'v:%d_e:%d' %\n",
    "                                        (r.video.ID, r.endpoint.ID))\n",
    "\n",
    "        #the tricky constrain to express as a mathematic disequation is the selection of the lowest latency\n",
    "        #i used slack variables collected in this list, and the Big M tecnique\n",
    "        #with this constrain i want to express that the request's latency is bigger than the caches latency.\n",
    "        #given that in the end i want to maximize the negation of this variable, this set of constrains will assure that\n",
    "        #req_min_latency will assume the value of the smallest latency among the caches that contains its video\n",
    "        min_cache_select = []\n",
    "        for c, c_l in r.endpoint.caches_latency:\n",
    "            #IntVar for video present in this cache\n",
    "            y = cache_video[c][r.video]\n",
    "            #Support IntVar to select the lowest latency among caches\n",
    "            b = solver.IntVar(0, 1, 'e:%d_v:%d_c:%d' %\n",
    "                              (r.endpoint.ID, r.video.ID, c.ID))\n",
    "            #Big_M (variation): if video in cache, req_min_latency is tied to this latency, \n",
    "            #otherwise it is tied to the datacenter latency\n",
    "            # b if 1 trasform this costrain in a tautology (so it doesn't matter anymore)\n",
    "            solver.Add(req_min_latency >= c_l + (1 - y) *\n",
    "                       (dc_L - c_l) - dc_L * b)\n",
    "            min_cache_select.append(b)\n",
    "\n",
    "        if len(r.endpoint.caches_latency) == 0:\n",
    "            #base case: no cache present or used\n",
    "            #this one is redundant in most cases\n",
    "            b = solver.IntVar(0, 1,\n",
    "                              'e:%d_v:%d_dc' % (r.endpoint.ID, r.video.ID))\n",
    "            solver.Add(req_min_latency >= dc_L - dc_L * b)\n",
    "            min_cache_select.append(b)\n",
    "\n",
    "        #Big_M for select: this will ensure that the minimun latency will be chosen, only one 'b' can be 0 in this set\n",
    "        solver.Add(solver.Sum(min_cache_select) == (len(min_cache_select) - 1))\n",
    "        #save the latency var to use it in the objective function\n",
    "        req_var[r] = req_min_latency\n",
    "\n",
    "    #the objective is to maximize the scoring function, and this is tied to the request latency (tied to the presence of a video in a cache) \n",
    "    solver.Maximize(\n",
    "        solver.Sum(\n",
    "            map(lambda r: r[0].quantity * (r[0].endpoint.datacenter_latency - r[1]),\n",
    "                req_var.items())) *\n",
    "        (1000 / sum(map(attrgetter('quantity'), req_var))))\n",
    "\n",
    "    #this is where the magic happens. warning, high memory and hight cpu time usage ahead\n",
    "    solver.Solve()\n",
    "\n",
    "    #finally, return the computed score, and a map cache:list(videos) to represent video's allocation inside the caches\n",
    "    return solver.Objective().Value(), {\n",
    "        c: list(\n",
    "            map(\n",
    "                itemgetter(0),\n",
    "                filter(lambda x: x[1].solution_value() == 1, vl.items())))\n",
    "        for c, vl in cache_video.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### A test dataset\n",
    "\n",
    "A small example to test the code I've written. This is taken from the [problem pdf](files/hashcode2017_streaming_videos.pdf)\n",
    "\n",
    "In the datacenter there are 5 videos, there are 3 caches of 100 mb each, and 2 endpoints connect to the datacenter. Only the first endpoint is connected to all the caches.\n",
    "\n",
    "Next we have the requests that will decide the score of my solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-15T12:24:56.354783Z",
     "start_time": "2017-03-15T13:24:56.279750+01:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "videoList = [\n",
    "    Video(ID=0, size=50), Video(ID=1, size=50), Video(ID=2, size=80),\n",
    "    Video(ID=3, size=30), Video(ID=4, size=110)\n",
    "]\n",
    "cacheList = [\n",
    "    Cache(ID=0, size=100), Cache(ID=1, size=100), Cache(ID=2, size=100)\n",
    "]\n",
    "endpointList = [\n",
    "    Endpoint(\n",
    "        ID=0,\n",
    "        datacenter_latency=1000,\n",
    "        caches_latency=[(cacheList[0], 100), (cacheList[1], 200), \n",
    "                        (cacheList[2], 300)]),\n",
    "    Endpoint(ID=1, datacenter_latency=500, caches_latency=[])\n",
    "]\n",
    "requestList = [\n",
    "    Request(quantity=1000, video=videoList[3], endpoint=endpointList[1]),\n",
    "    Request(quantity=1500, video=videoList[3], endpoint=endpointList[0]),\n",
    "    Request(quantity=500, video=videoList[4], endpoint=endpointList[0]),\n",
    "    Request(quantity=1000, video=videoList[1], endpoint=endpointList[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T08:42:58.730552Z",
     "start_time": "2017-03-09T09:42:58.715156+01:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### The moment of truth\n",
    "\n",
    "if all goes well nothing will explode (a lot of things exploded before arriving at this point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-15T12:24:56.569833Z",
     "start_time": "2017-03-15T13:24:56.357553+01:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the video from the solution fit into the caches:  True\n",
      "actual score:  562500\n",
      "score from the mpiSolver:  562500\n",
      "score:  562500.0\n",
      "in cache 1 are present video1, video3\n",
      "in cache 0 are present video1, video3\n",
      "in cache 2 are present video1, video3\n"
     ]
    }
   ],
   "source": [
    "value, res = mpiSolver(videoList, cacheList, endpointList, requestList)\n",
    "verifySolution(value, res, requestList)\n",
    "summaryPrinter(value, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Nice! the execution time for the above cell on my laptop is ~70 ms.\n",
    "In contrast, in the first iteration i implemented the CP solver and i got ~3000 ms of execution time\n",
    "\n",
    "Notice that for the scoring function only cache 0 is important, has it has the lowest latency to the endpoint.\n",
    "also, if you look at the test dataset you'll see that video4 is too big to fit in a cache, so it was not considerate for the solution. \n",
    "\n",
    "now it's time to test a dataset. Here i implement a function to load a dataset from file (as in the problem specification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-15T12:24:56.669902Z",
     "start_time": "2017-03-15T13:24:56.572178+01:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from operator import attrgetter\n",
    "from itertools import groupby\n",
    "from functools import reduce\n",
    "\n",
    "#not the best way to do it\n",
    "def readFromFile(filename):\n",
    "    datain = open(filename)\n",
    "    header = datain.readline()\n",
    "    #nice trick to extract formatted input into variables\n",
    "    n_vid, n_endp, n_req, n_caches, size_caches = [\n",
    "        f(i) for f, i in zip([int, int, int, int, int], header.split())\n",
    "    ]\n",
    "    cacheList = [Cache(ID=id, size=size_caches) for id in range(n_caches)]\n",
    "    vids = datain.readline()\n",
    "    videoList = [\n",
    "        Video(ID=id, size=int(s)) for id, s in zip(range(n_vid), vids.split())\n",
    "    ]\n",
    "    endpointList = []\n",
    "    for id in range(n_endp):\n",
    "        descr = datain.readline()\n",
    "        dc_lat, c_cach = [f(i) for f, i in zip([int, int], descr.split())]\n",
    "        caches = []\n",
    "        for c in range(c_cach):\n",
    "            cache_descr = datain.readline()\n",
    "            c_id, c_lat = [\n",
    "                f(i) for f, i in zip([int, int], cache_descr.split())\n",
    "            ]\n",
    "            caches.append((cacheList[c_id], c_lat))\n",
    "        endpointList.append(\n",
    "            Endpoint(ID=id, caches_latency=caches, datacenter_latency=dc_lat))\n",
    "    requestList = []\n",
    "    for _ in range(n_req):\n",
    "        req_descr = datain.readline()\n",
    "        vid, endp, quant = [\n",
    "            f(i) for f, i in zip((int, int, int), req_descr.split())\n",
    "        ]\n",
    "        requestList.append(\n",
    "            Request(\n",
    "                quantity=quant,\n",
    "                endpoint=endpointList[endp],\n",
    "                video=videoList[vid]))\n",
    "\n",
    "    #the tricky part: turns out that in the input dataset the requests are not completely aggregated\n",
    "    #by this i mean that there are multiple requests with the same (endpoint,video) pair.\n",
    "    #here i aggregate them, since mathematically the result is the same, and the solver likes it better this way\n",
    "    req_comp = attrgetter('video.ID', 'endpoint.ID')\n",
    "    rsorted=[reduce(lambda r1, r2: Request(video=r1.video, endpoint=r1.endpoint, quantity=r1.quantity+r2.quantity), g) for _, g in groupby(sorted(requestList, key=req_comp), key=req_comp)]\n",
    "\n",
    "    return dict(\n",
    "        caches=cacheList,\n",
    "        videos=videoList,\n",
    "        endpoints=endpointList,\n",
    "        requests=rsorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-15T12:24:56.836025Z",
     "start_time": "2017-03-15T13:24:56.673032+01:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#load the smallest dataset, 78kb\n",
    "small_problem = readFromFile('me_at_the_zoo.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-15T12:27:09.718361Z",
     "start_time": "2017-03-15T13:24:56.838740+01:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the video from the solution fit into the caches:  True\n",
      "actual score:  516557\n",
      "score from the mpiSolver:  516557\n",
      "score:  516557.9336347092\n",
      "in cache 3 are present video10, video1, video5, video2, video4, video24, video16\n",
      "in cache 2 are present video1, video31, video8, video5\n",
      "in cache 9 are present video5, video23, video43, video4, video0, video16\n",
      "in cache 5 are present video13, video10, video8, video0, video81\n",
      "in cache 0 are present video15, video10, video5, video0, video82, video16, video46\n",
      "in cache 1 are present video13, video6, video99, video7, video1, video65, video16\n",
      "in cache 8 are present video10, video2, video3, video0\n",
      "in cache 6 are present video30, video1, video5, video27, video4, video0, video16\n",
      "in cache 7 are present video54, video74, video1, video21, video5\n",
      "in cache 4 are present video17, video32, video3, video4\n"
     ]
    }
   ],
   "source": [
    "value, res = mpiSolver(small_problem['videos'], small_problem['caches'],\n",
    "                       small_problem['endpoints'], small_problem['requests'])\n",
    "verifySolution(value, res, small_problem['requests'])\n",
    "summaryPrinter(value, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "It works! and only 130 seconds and 60mb to find a solution.\n",
    "\n",
    "I tried the second dataset and after 5Gb of memory and half hour of computation the end was not in is sight, so it's pretty safe to say that this way of solving this problem is not particularly viable. Has i wrote at the start of this notebook, a dividi et impera solution, where only a small fraction of the requests are analyzed each time might produce good enough results."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
